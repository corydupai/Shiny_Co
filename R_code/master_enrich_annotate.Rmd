---
title: "master_enrich_annotate"
author: "Tanvi Ingle"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(seqinr) # may have issues with installation
library(parallel)
library(WGCNA)
library(data.table)
library(tidyverse)
library(tidygraph) # issues with installation 
library(ggrepel)
library(cowplot)
library(ggraph) # may have issues with installation 
library(igraph)
library(DOSE)
library(parallel)
library(europepmc)
library(clusterProfiler) # requires ggplotify
library(KEGGREST)  # may have issues with installation
library(qdapTools) # may have issues with installation
library(OpenImageR)
```

# Get Bacteria Directory 
```{r}
basedir <- "/stor/work/Wilke/tingle/WGCNA_expanded/bacteria/"
bacdir <- "K.pneumoniae/"
bac_initials <- "kp"
bac_name <- "Klebsiella pneumoniae"
```

# Get Bacterial Files
```{r}
cutoff_9 <- list2df(read.fasta(paste0(basedir, bacdir, "cutoff_9.fasta")))
match.table <- read.table(paste0(basedir, bacdir, "/panoct_output/pangenome/results/matchtable.txt"), header = FALSE) 
```

# Step 1:
## Filter `match.table` based on Filtered centroids.fasta file (cutoff_9)
`match.table` has a list of genes associated with each ortholog used to construct the pangenome
`cutoff_9` filtered out orthologs from `match.table` with less than 9 genes 
```{r}
# Fornat centroids file 
centroids_to_annotation <- cutoff_9 %>% 
  select(-X1) %>% 
  mutate(centroid = X2) %>% 
  separate(`X2`, c("centroid_text", "id_number"), "_" ) %>% 
  select(-centroid_text) %>% 
  summarise(id_number = unique(id_number), centroid = unique(centroid)) 

# Merge centroids & match table to filter; make longer
filter_match_table <- match.table %>% 
  rename(id_number = V1) %>% 
  merge(centroids_to_annotation, by="id_number") %>% 
  pivot_longer(-id_number) %>% 
  select(-name) %>% 
  rename(loci = value)

# Clean up environment
remove(cutoff_9, centroids_to_annotation)
```

# Step 2: Find genes & corresponding function
## Get KEGG Identifiers -- (https://www.genome.jp/kegg/catalog/org_list.html)
In the KEGG database, each reference geneome for each organism has an associated `T()` code. The `keggList()` function pulls gene loci identifiers affiliated with the `T()`, formatted as `organism_code:gene_loci` along with the protein annotation. This dataframe of gene loci is then filtered based off of loci in the `filter_match_table`, and stored as `bac_entries`. 

I've written the `get_annotations.func()` to call `keggGet()` on each loci, which retrieves all associated database entries. **Unfortunately, I can't parallelize this function call--I think there's some issue with how many times I can ping the database. So this takes a veeerrry long time. Ideas** The annotations are saved as a .csv file for future reference. Then we filter these entries to only include Kegg Codes and save this as a `~filtered_annotations.csv`. 
```{r}
# Get T() Number for all reference genomes & call keggList() for organism name:gene loci keys. 
t_codes <- as.vector(read.csv(paste0(basedir, bacdir, "tcodes.csv"))$x) 

# Get all org_id:loci associated with each t_code 
reference_t <- data.frame()
for(t in t_codes)
{
  kegg_t <- list2df(keggList(t)) %>% 
    transmute(`protein_annotation` = X1, `org_loci` = X2)
  
  reference_t <- rbind(reference_t, kegg_t)
}

# Filter entries in reference_t by gene loci in filter_match_table
bac_entries <- reference_t %>% 
  mutate(temp = org_loci) %>% 
  separate(temp, c("org", "loci"), sep = ":") %>% 
  merge(filter_match_table, by="loci") 
  
# Function to get annotations and format into dataframe
get_annotations.func <- function(loci)
{
  print(loci)
  gene.df <- list2df(keggGet(loci))[1,]
  return(gene.df)
}

# Get annotations for each gene:loci combination

############# WRITE ####################
# bac_annotations <- lapply(bac_entries$org_loci, get_annotations.func)
# 
# bac_annotations.df <- list2df(bac_annotations)
# 
# write.csv(bac_annotations.df,paste0(basedir, bacdir, "annotations.csv"))
# 
# bac_annotations.df <- read.csv(paste0(basedir, bacdir, "annotations.csv"))
# 
# bac_filtered <- bac_annotations.df %>% 
#    group_by(X2) %>% 
#    mutate(loci = X1[1], protein = X1[2], centroid = paste0("centroid_", X2)) %>% 
#    filter(stringr::str_detect(X1, stringr::regex("[:blank:]\\d\\d")) |
#           stringr::str_detect(X1, stringr::regex("[:blank:]\\d\\."))) %>%
#    filter(!stringr::str_detect(X1, stringr::regex(bac_name))) %>% 
#    rename(annotations = X1, id_number = X2) %>% 
#    merge(bac_entries, by = c("id_number")) %>% 
#    select(-id_number, -org_loci, -org, -loci.x) %>% 
#    select(centroid, loci.y, protein, protein_annotation, annotations) %>% 
#    arrange(centroid) %>% 
#   group_by(centroid, annotations) %>% 
#   summarise(protein = unique(protein))
# 
# write.csv(bac_filtered, paste0(basedir, bacdir, bac_initials, "_filtered_annotations.csv"))

```


## Get GO Annotations
To access the GO annotations for each loci, I downloaded the list of loci locally and uploaded it to the DAVID website (https://david.ncifcrf.gov/). DAVID had GO terms for 5,227 of the 397,052 loci (which I suppose is reasonable since klebsiella may just not be that extensively annotated). *Does anyone know how to do this straight from R? It doesn't take long...just annoying*. 
```{r}
# Clean up list of loci from filter_match_table
bac_loci <- filter_match_table %>% 
  filter(loci != "----------") %>% 
  filter(!str_detect(loci, stringr::regex("centroid_\\d")))
  
## Write list of loci to a txt file & Download locally
# write(bac_loci$loci, file = paste0(basedir, bacdir, bac_initials, "_loci.txt"))

# Upload local list of loci to DAVID website & run
## Notes - 391,825 unknown, 5227 DAVID Ids (line 1 is header) 
## Upload output txt file with GO terms
kp_GOterms <- read.delim("/stor/work/Wilke/tingle/WGCNA_expanded/bacteria/K.pneumoniae/kp_GOterms.txt",
                         sep="\t", 
                         header=TRUE, 
                         comment.char="#", na.strings=".", 
                         stringsAsFactors=FALSE,
                         quote="", 
                         fill=TRUE)
```













